# Klasifikacija Bolesti Biljaka KoriÅ¡Ä‡enjem Semi-Supervised GAN-a

## ğŸ“‹ Pregled Projekta

Ovaj projekat implementira **Semi-Supervised Generative Adversarial Network (SGAN)** za klasifikaciju bolesti biljaka na osnovu slika listova. Implementacija je zasnovana na nauÄnom radu sa Stanforda: [Plant Disease Classification Using Convolutional Networks and Generative Adversarial Networks](https://cs231n.stanford.edu/reports/2017/pdfs/325.pdf).

### ğŸ¯ Cilj

Identifikacija bolesti biljaka iz fotografija listova, Å¡to omoguÄ‡ava brÅ¾e intervencije i smanjenje uticaja bolesti na prinos hrane. Ovo je posebno vaÅ¾no za male farmere u zemljama u razvoju gde se 80% poljoprivredne proizvodnje generiÅ¡e na malim gazdinstvima.

### ğŸ”¬ Å ta Je Semi-Supervised GAN?

Tradicionalni GAN (Generative Adversarial Network) se sastoji od dva dela:
1. **Generator (G)** - generiÅ¡e "laÅ¾ne" slike iz nasumiÄnog Å¡uma
2. **Diskriminator (D)** - razlikuje prave slike od generisanih

**Semi-Supervised GAN** proÅ¡iruje ovu arhitekturu tako Å¡to diskriminator postaje i **klasifikator (D/C)**:
- Umesto binarne klasifikacije (pravo/laÅ¾no), D/C klasifikuje slike u `N+1` klasa
- `N` pravih klasa (vrste bolesti + zdrave biljke)
- `1` dodatna klasa za "laÅ¾ne" slike iz generatora

**KljuÄna prednost**: SGAN postiÅ¾e bolje rezultate od obiÄnih CNN mreÅ¾a kada imamo **mali skup podataka** za obuÄavanje, jer generator pomaÅ¾e u uÄenju boljeg predstavljanja podataka.

## ğŸ“Š Skup Podataka

Projekat koristi skup od **86,147 slika** bolenih i zdravih listova biljaka:
- **Trening set**: 55,135 slika
- **Validacioni set**: 13,783 slika
- **Test set**: 17,229 slika

### Klase Biljaka i Bolesti

Skup sadrÅ¾i 15 razliÄitih kategorija:
- **Paprika**: Bakterijska pegavost, Zdrava
- **Krompir**: Rana pegavost, Zdrav, Kasna pegavost
- **Paradajz**: PlamenjaÄa, Bakterijska pegavost, Rana pegavost, Zdrav, Kasna pegavost, Plesni, Septorijska pegavost listova, Grinje, Virus mozaika, Virus Å¾utila listova

## ğŸ—ï¸ Arhitektura MreÅ¾e

### Generator

Generator prati poboljÅ¡anu arhitekturu iz rada:
```
Ulaz: Vektor Å¡uma (100 dimenzija)
â†“
Linear (100 â†’ 1024) + BatchNorm + ReLU
â†“
Linear (1024 â†’ 131,072) + BatchNorm + ReLU
â†“
Unflatten â†’ 128 Ã— 32 Ã— 32
â†“
ConvTranspose2d (128 â†’ 64, kernel=4, stride=2)
â†“
ConvTranspose2d (64 â†’ 32, kernel=4, stride=2)
â†“
ConvTranspose2d (32 â†’ 16, kernel=1)
â†“
Conv2d + MaxPool2d
â†“
Izlaz: Slika 3 Ã— 64 Ã— 64
```

### Diskriminator/Klasifikator (D/C)

D/C mreÅ¾a prati arhitekturu iz rada sa dubokim konvolucionim slojevima:
```
Ulaz: Slika 3 Ã— 64 Ã— 64
â†“
Conv2d (3 â†’ 128, kernel=5) + LeakyReLU + MaxPool2d
â†“
Conv2d (128 â†’ 64, kernel=5) + LeakyReLU + MaxPool2d
â†“
Conv2d (64 â†’ 32, kernel=5) + LeakyReLU + MaxPool2d
â†“
Flatten
â†“
Linear (512 â†’ 1024) + LeakyReLU
â†“
Linear (1024 â†’ NUM_CLASSES + 1)
â†“
Izlaz: Logits za N+1 klasa
```

## ğŸ”§ Funkcije Gubitka

### Gubitak Diskriminatora

Implementiran **taÄno kao u radu**:
```python
def discriminator_loss(logits_real, logits_fake, true_labels, softmax_loss):
    N, C = logits_real.size()
    fake_labels = (torch.zeros(N) + (C - 1)).long()
    return softmax_loss(logits_real, true_labels) + softmax_loss(logits_fake, fake_labels)
```

Gubitak je zbir:
1. Cross-entropy gubitak za prave slike (klasifikacija u N klasa)
2. Cross-entropy gubitak za laÅ¾ne slike (klasifikacija u "laÅ¾nu" klasu)

### Gubitak Generatora

Generator Å¾eli da prevari D/C - da laÅ¾ne slike budu klasifikovane kao neka od pravih klasa:
```python
def generator_loss(logits_fake, num_classes):
    # Cilj: uniformna distribucija preko pravih klasa
    target_probs = torch.ones(N, num_classes) / num_classes
    real_class_logits = logits_fake[:, :num_classes]
    return F.kl_div(F.log_softmax(real_class_logits, dim=1), target_probs, reduction='batchmean')
```

## ğŸš€ Kako Pokrenuti Projekat

### Preduslov

- Python 3.12 ili noviji
- `uv` menadÅ¾er paketa ([instalacija](https://github.com/astral-sh/uv))

### 1. Instalacija Zavisnosti

```bash
# uv automatski Äita pyproject.toml i instalira zavisnosti
uv sync
```

### 2. Preuzimanje Skupa Podataka

Skup podataka treba da bude organizovan u sledeÄ‡oj strukturi:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Pepper__bell___Bacterial_spot/
â”‚   â”œâ”€â”€ Pepper__bell___healthy/
â”‚   â”œâ”€â”€ Potato___Early_blight/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â””â”€â”€ (ista struktura)
â””â”€â”€ test/
    â””â”€â”€ (ista struktura)
```

MoÅ¾ete koristiti `download_dataset.py` skriptu za automatsko preuzimanje:
```bash
uv run python download_dataset.py
```

### 3. Trening Modela

```bash
uv run python semisupervised_plant_classification.py
```

#### Parametri Treninga

MoÅ¾ete prilagoditi parametre u `train_model()` funkciji:
- `num_epochs`: Broj epoha (podrazumevano: 10)
- `lr`: Learning rate (podrazumevano: 0.0001)
- `noise_dim`: Dimenzija vektora Å¡uma (podrazumevano: 100)
- `batch_size`: VeliÄina batch-a (podrazumevano: 32)

### 4. Evaluacija Modela

Evaluacija se automatski pokreÄ‡e nakon treninga. MoÅ¾ete je pokrenuti i ruÄno:
```python
from semisupervised_plant_classification import evaluate_discriminator
evaluate_discriminator("dc_discriminator")
```

## ğŸ“ˆ OÄekivani Rezultati

### Tokom Treninga

- **Gubitak Diskriminatora (Loss_DC)**: Trebao bi da se smanjuje i stabilizuje oko 1.0-2.0
- **Gubitak Generatora (Loss_G)**: Trebao bi da oscilira i polako se smanjuje
- **Vreme treninga**: ~10-30 minuta po epohi (zavisno od hardvera)

### Nakon Treninga

Program generiÅ¡e:

1. **Grafikon gubitaka** (`sgan_losses.png`)
   - Prikaz Loss_DC i Loss_G tokom iteracija
   - OmoguÄ‡ava vizuelnu proveru konvergencije

2. **Matrica konfuzije** (`sgan_confusion_matrix.png`)
   - Heatmap koja prikazuje performanse po klasama
   - Dijagonala pokazuje taÄne predikcije
   - Van-dijagonalni elementi pokazuju greÅ¡ke

3. **IzveÅ¡taj o klasifikaciji**
   ```
   TaÄnost SGAN Klasifikatora na test skupu: 0.7800 (78.00%)
   
   Detaljan IzveÅ¡taj Klasifikacije:
                                    precision    recall  f1-score   support
   pepper_0                            0.85      0.82      0.83       500
   pepper_1                            0.79      0.81      0.80       450
   ...
   ```

### OÄekivane Performanse (Prema Radu)

- **TaÄnost na test skupu**: 69-78% (zavisno od arhitekture)
- **PoboljÅ¡anje**: SGAN radi bolje od obiÄnog CNN-a kada je skup podataka mali
- **Baseline (ResNet)**: ~80% taÄnosti sa velikim skupom podataka

## ğŸ“‚ Struktura Projekta

```
Plant-Disease-Classification/
â”œâ”€â”€ semisupervised_plant_classification.py  # Glavna implementacija
â”œâ”€â”€ conditional_gan.py                      # Conditional GAN (eksperiment)
â”œâ”€â”€ sgan_plant_disease.py                   # Alternativna SGAN implementacija
â”œâ”€â”€ download_dataset.py                     # Skript za preuzimanje podataka
â”œâ”€â”€ imageutils.py                           # PomoÄ‡ne funkcije za slike
â”œâ”€â”€ pyproject.toml                          # Zavisnosti projekta
â”œâ”€â”€ dc_discriminator.pth                    # SaÄuvan D/C model
â”œâ”€â”€ sgan_confusion_matrix.png               # Matrica konfuzije
â”œâ”€â”€ data/                                   # Skup podataka
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ README.md                               # Ova dokumentacija
```

## ğŸ”¬ TehniÄki Detalji

### Augmentacija Podataka

Trening set koristi:
- `RandomHorizontalFlip(0.5)` - NasumiÄno horizontalno okretanje
- `RandomRotation(10)` - NasumiÄna rotacija do Â±10Â°
- `Resize((64, 64))` - Skaliranje na 64Ã—64 piksela
- `Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))` - Normalizacija u [-1, 1]

### Optimizacija

- **Optimizator**: Adam sa `betas=(0.5, 0.999)`
- **Learning rate**: 0.0001 (kao u radu)
- **Batch size**: 32

### UreÄ‘aj za Trening

Kod automatski detektuje dostupan hardver:
- **MPS** (Apple Silicon - M1/M2/M3)
- **CUDA** (NVIDIA GPU)
- **CPU** (fallback)

```python
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
```

## ğŸ¤” ZaÅ¡to SGAN, a ne obiÄan CNN?

**Prednosti SGAN-a**:
1. **Bolje performanse sa malim skupovima podataka**
   - Generator pomaÅ¾e D/C da nauÄi bolje reprezentacije
   - Regularizacija kroz adversarial trening

2. **Robusnost**
   - Manje overfitting-a
   - Bolja generalizacija na nove podatke

3. **Implicitna augmentacija podataka**
   - Generator stvara "virtuelne" primere
   - Diskriminator uÄi da razlikuje distribucije

**Kada koristiti CNN umesto SGAN**:
- Kada imate **veliki skup podataka** (>100k slika)
- Kada je vreme treninga kritiÄno (CNN je brÅ¾i)
- Kada je jednostavnost vaÅ¾nija od performansi

## ğŸ“š Reference

1. **Glavni Rad**:
   - Emanuel Cortes (2017). "Plant Disease Classification Using Convolutional Networks and Generative Adversarial Networks"
   - Stanford University CS231n
   - [PDF Link](https://cs231n.stanford.edu/reports/2017/pdfs/325.pdf)

2. **Povezani Radovi**:
   - Mohanty et al. (2016). "Using Deep Learning for Image-Based Plant Disease Detection"
   - Odena et al. (2016). "Semi-Supervised Learning with Generative Adversarial Networks"

3. **Dataset**:
   - PlantVillage Dataset (86,147 slika, 25 vrsta biljaka)

## ğŸ› ï¸ Troubleshooting

### Problem: "Out of Memory" greÅ¡ka

**ReÅ¡enje**: Smanjite `batch_size` u `train_model()`:
```python
batch_size = 16  # ili 8
```

### Problem: Spor trening na CPU

**ReÅ¡enje**: 
- Smanjite `num_epochs` na 5
- Smanjite dimenzije slike na 32Ã—32
- Koristite GPU ako je dostupan

### Problem: Generator ne konvergira

**Simptomi**: Loss_G raste ili ne pada
**ReÅ¡enje**:
- Smanjite learning rate za generator: `lr=0.00005`
- PoveÄ‡ajte broj D/C koraka pre G koraka
- Proverite balans izmeÄ‘u Loss_DC i Loss_G

### Problem: LoÅ¡a taÄnost (<50%)

**MoguÄ‡i uzroci**:
1. Premalo epoha - poveÄ‡ajte `num_epochs` na 20-50
2. Previsok learning rate - smanjite na `1e-5`
3. NeujednaÄen skup podataka - proverite distribuciju klasa

## ğŸ“§ Kontakt i Doprinosi

Ovaj projekat je edukativna implementacija za istraÅ¾ivaÄke svrhe. Za pitanja, predloge ili doprinose, molimo:
1. Otvorite Issue na GitHub-u
2. PoÅ¡aljite Pull Request sa opisom promena
3. Uverite se da kodujete u skladu sa postojeÄ‡im stilom

## ğŸ“„ Licenca

Ovaj projekat je otvorenog koda i namenjen je za edukativne i istraÅ¾ivaÄke svrhe.

---

**Napomena**: Rezultati mogu varirati u zavisnosti od hardvera, parametara treninga i specifiÄnog skupa podataka. Za najbolje rezultate, preporuÄuje se eksperimentisanje sa hiperparametrima i arhitekturom mreÅ¾e.

**Sretno sa klasifikacijom bolesti biljaka! ğŸŒ±ğŸ”¬**

